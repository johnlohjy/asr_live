{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define ASR Model and dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import time\n",
    "\n",
    "# Model setup code for distil-whisper small\n",
    "model_id = \"distil-whisper/distil-small.en\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Define dataset for testing\n",
    "dataset_repo = \"johnlohjy/imda_nsc_p3_same_closemic_train\"\n",
    "dataset = load_dataset(dataset_repo, split='train', streaming=True, trust_remote_code=True)\n",
    "dataset_iter = iter(dataset)\n",
    "sample = next(dataset_iter)\n",
    "sample = sample[\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define Server-Related Classes, Adapted for Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import wave\n",
    "\n",
    "class Client:\n",
    "    def __init__(self):\n",
    "        self.frames_np = None # To store frames buffer as a numpy array\n",
    "        self.timestamp_offset = 0.0 # Track transcription offset from the very start\n",
    "        self.frames_offset = 0.0 # Track frames offset from the very start/Duration of audio discarded\n",
    "        self.send_last_n_segments = 10  # Number of transcribed segments that will be 'sent' to the client\n",
    "        \n",
    "\n",
    "\n",
    "    def add_frames(self, frame_np):\n",
    "        '''\n",
    "        Add new audio chunks to frames buffer\n",
    "\n",
    "        Check if need lock in the future\n",
    "        '''\n",
    "        if self.frames_np is None:\n",
    "            # If the frames buffer is empty, initialise it with the new audio frames\n",
    "            self.frames_np = frame_np.copy()\n",
    "        else:\n",
    "            # Append the new audio chunk to the existing frames buffer\n",
    "            self.frames_np = np.concatenate((self.frames_np, frame_np), axis=0)\n",
    "\n",
    "    def save_frames(self):\n",
    "        '''\n",
    "        Sample code to save the audio when client disconnects\n",
    "        '''\n",
    "        fp = os.path.join(os.getcwd(), \"test_frames.wav\")\n",
    "        with wave.open(fp, \"wb\") as wavfile:\n",
    "            wavfile: wave.Wave_write\n",
    "            wavfile.setnchannels(1)\n",
    "            wavfile.setsampwidth(2)\n",
    "            wavfile.setframerate(16000)\n",
    "            wavfile.writeframes(self.frames_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ClientManager:\n",
    "    '''\n",
    "    Custom client manager class to handle clients connected over the \n",
    "    WebSocket server\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.clients = {}\n",
    "\n",
    "    def add_client(self, websocket, client):\n",
    "        '''\n",
    "        Add a WebSocket server connection info and its associated client\n",
    "        '''\n",
    "        self.clients[websocket] = client\n",
    "\n",
    "    def get_client(self, websocket):\n",
    "        '''\n",
    "        Retrieve a client associated with the WebSocket server connection info provided\n",
    "        '''\n",
    "        if websocket in self.clients:\n",
    "            return self.clients[websocket]\n",
    "        return False \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Server:\n",
    "    '''\n",
    "    Server class handles\n",
    "    - New client connections\n",
    "    - Receiving and processing audio from client\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.client_manager = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def initialize_client(self, websocket):\n",
    "        '''\n",
    "        Initialize the new client and add it to the client manager\n",
    "\n",
    "        EXPAND ON CLIENT CLASS (see ServeClientTensorRT, ServeClientBase)\n",
    "        '''\n",
    "        # Initialize the client\n",
    "        client = Client()\n",
    "\n",
    "        # Add the client to the client manager\n",
    "        self.client_manager.add_client(websocket, client)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def handle_new_connection(self,websocket):\n",
    "        '''\n",
    "        Initialise the client manager\n",
    "        Initialise the new client and add it to the client manager\n",
    "        '''\n",
    "\n",
    "        # Initialise the client manager if not done\n",
    "        if self.client_manager is None:\n",
    "            self.client_manager = ClientManager()\n",
    "\n",
    "        # Initialise the new client and add it to the client manager\n",
    "        self.initialize_client(websocket)\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def get_audio_from_websocket(self, websocket):\n",
    "        '''\n",
    "        Receive audio chunks from the WebSocket and create a numpy array out of it\n",
    "        '''\n",
    "        # Subsequently, receive audio data (message) over the WebSocket server connection\n",
    "        # https://websockets.readthedocs.io/en/stable/reference/sync/server.html#websockets.sync.server.ServerConnection.recv\n",
    "        frame_data = websocket.recv()\n",
    "\n",
    "        # Creates numpy array without copying it (more efficient)\n",
    "        return np.frombuffer(frame_data, dtype=np.float32)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def process_audio_frames(self, websocket):\n",
    "        '''\n",
    "        Get the audio chunk from the WebSocket as a numpy array\n",
    "\n",
    "        Send a dummy transcription back to the client first\n",
    "        '''\n",
    "        # Get the audio chunk from the WebSocket as a numpy array\n",
    "        frame_np = self.get_audio_from_websocket(websocket)\n",
    "        print('\"Received\" audio chunk')\n",
    "        # Get the client using its associated WebSocket\n",
    "        client = self.client_manager.get_client(websocket)\n",
    "\n",
    "        client.add_frames(frame_np)\n",
    "\n",
    "        # Send a dummy transcription\n",
    "        # https://websockets.readthedocs.io/en/stable/reference/sync/server.html#websockets.sync.server.ServerConnection.send\n",
    "        # ServerConnection provides recv() and send() methods for receiving and sending messages.\n",
    "        websocket.send(\n",
    "            json.dumps({\n",
    "                \"test\": \"test response\",\n",
    "            })\n",
    "        )\n",
    "\n",
    "        return True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def recv_audio(self,websocket):\n",
    "        \"\"\"\n",
    "        First handle the new connection\n",
    "\n",
    "        Continously process audio frames\n",
    "        \"\"\"\n",
    "\n",
    "        # Try to handle the new connection\n",
    "        if not self.handle_new_connection(websocket):\n",
    "            return\n",
    "        \n",
    "        # Continously process audio frames\n",
    "        while True: \n",
    "            if not self.process_audio_frames(websocket):\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loop to simulate sending server audio data (from file) and Server sending client transcription (print)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
