{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Test distil-whisper**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**distill-small**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets bitsandbytes accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "import time\n",
    "\n",
    "# Model setup code\n",
    "model_id = \"distil-whisper/distil-small.en\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset_repo = \"johnlohjy/imda_nsc_p3_same_closemic_train\"\n",
    "dataset = load_dataset(dataset_repo, split='train', streaming=True, trust_remote_code=True)\n",
    "dataset_iter = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\miniconda3\\envs\\myenv2\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The transcripton is {'text': \" You can go first? You guys are gonna stand here? They're like, well, this is a weird topic. Singapore and Malaysia are like, you know, brothers, but not really brothers, brothers on a tricky relationship. You know what, let's keep this topic. Next, do I go next? Do I go next? Okay, Hingsui, what's the best worst thing, best or worst thing that can happen to you in Singapore?\"} \n",
      "\n",
      "It took 19.30585479736328\n"
     ]
    }
   ],
   "source": [
    "sample = next(dataset_iter)\n",
    "sample = sample[\"audio\"]\n",
    "start_time = time.time()\n",
    "result = pipe(sample)\n",
    "end_time = time.time()\n",
    "print(f'The transcripton is {result} \\n')\n",
    "print(f'It took {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(dataset_iter)\n",
    "sample = sample[\"audio\"]\n",
    "start_time = time.time()\n",
    "result = pipe(sample)\n",
    "end_time = time.time()\n",
    "print(f'The transcripton is {result} \\n')\n",
    "print(f'It took {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(dataset_iter)\n",
    "sample = sample[\"audio\"]\n",
    "start_time = time.time()\n",
    "result = pipe(sample)\n",
    "end_time = time.time()\n",
    "print(f'The transcripton is {result} \\n')\n",
    "print(f'It took {end_time-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(dataset_iter)\n",
    "sample = sample[\"audio\"]\n",
    "start_time = time.time()\n",
    "result = pipe(sample)\n",
    "end_time = time.time()\n",
    "print(f'The transcripton is {result} \\n')\n",
    "print(f'It took {end_time-start_time}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
